{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一个模型：全连接模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Sequential_是实现全连接网络的最好方式。但从简单的全连接网络学习内容，需要理解这几个概念：\n",
    "* 层对象接受张量为参数，返回一个张量  \n",
    "* 输入是张量，输出也是张量的一个框架就是一个模型，通过_Model_定义  \n",
    "* 这样的模型可以像_Sequential_一样被训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 2.7713 - acc: 0.1000\n",
      "Epoch 2/10\n",
      "100/100 [==============================] - 0s 371us/step - loss: 2.2933 - acc: 0.1700\n",
      "Epoch 3/10\n",
      "100/100 [==============================] - 0s 255us/step - loss: 2.2248 - acc: 0.1700\n",
      "Epoch 4/10\n",
      "100/100 [==============================] - 0s 296us/step - loss: 2.1571 - acc: 0.1900\n",
      "Epoch 5/10\n",
      "100/100 [==============================] - 0s 321us/step - loss: 2.1227 - acc: 0.2400\n",
      "Epoch 6/10\n",
      "100/100 [==============================] - 0s 316us/step - loss: 2.0835 - acc: 0.2200\n",
      "Epoch 7/10\n",
      "100/100 [==============================] - 0s 331us/step - loss: 2.0390 - acc: 0.2800\n",
      "Epoch 8/10\n",
      "100/100 [==============================] - 0s 351us/step - loss: 2.0189 - acc: 0.3200\n",
      "Epoch 9/10\n",
      "100/100 [==============================] - 0s 336us/step - loss: 1.9670 - acc: 0.3000\n",
      "Epoch 10/10\n",
      "100/100 [==============================] - 0s 251us/step - loss: 1.9536 - acc: 0.3400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x21522d9bf60>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "\n",
    "#This returns a tensor\n",
    "inputs=Input(shape=(784,))\n",
    "\n",
    "#a layer instance is callable on a tensor,and returns a tensor(一个层实例可以在一个张量上调用，并返回一个张量)\n",
    "x=Dense(64,activation='relu')(inputs)\n",
    "x=Dense(64,activation='relu')(x)\n",
    "predictions=Dense(10,activation='softmax')(x)\n",
    "\n",
    "import numpy as np\n",
    "import keras\n",
    "data = np.random.random((100, 784))\n",
    "labels = keras.utils.to_categorical(np.random.randint(10, size=(100, 1)), num_classes=10)\n",
    "\n",
    "#This creates a model that includes\n",
    "#the input layer and three Dense Layers\n",
    "model=Model(inputs=inputs,outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.fit(data,labels,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型都是**可调用的**的，就想层一样"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用函数式模型的接口，可以很容易的重用已经训练好的模型：你可以吧模型当做层一样，通过提供一个tensor来调用，注意：当你调用一个模型时，不仅重用了它的结构，也重用了它的权重。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input,Dense\n",
    "from keras.models import Model\n",
    "\n",
    "x=Input(shape=(784,))\n",
    "y=model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种方式可以允许我们快速创建能处理序列信号的模型，可以很快将一个图像分类的模型变为一个队视频分类的模型，只需要一行代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "#input tensor for sequences of 20 timesteps\n",
    "#each containing a 784_dimensional vector\n",
    "input_sequences=Input(shape=(20,784))\n",
    "#This applies our previous model to every timestep in the input  sequences\n",
    "#the output of the previous model was a 10-way softmax\n",
    "#so the output of the layer below will be a sequence of 20 vectors of size 10\n",
    "processed_sequences=TimeDistributed(model)(input_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 多输入和多输出模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用函数式模型的一个典型场景是搭建多输入、多输出的模型。  \n",
    "考虑这样一个模型，我么希望预测twitter上一条新闻被转发的次数。模型的主要输入是新闻本身，也就是一个词语的序列，但我们还可以拥有额外的输入，如日期等。这个模型的损失函数由两部分构成，辅助的损失函数评估仅仅基于新闻本身做出预测的情况，主损失函数评估基于新闻和额外信息的预测的情况，即使来自主损失函数打的梯度发生弥散，来自辅助损失函数的信息也能够训练Embedding和LSTM层。在模型中早点使用主要的损失函数是对于深度网络的一个良好的正则方法。\n",
    "![](https://keras-cn.readthedocs.io/en/latest/images/multi-input-multi-output-graph.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "主要的输入是接收新闻本身，即一个整数的序列（每个整数编码了一个词），这些整数位于1到10000之间，这个序列有100个单词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input,Embedding,LSTM,Dense\n",
    "from keras.models import Model\n",
    "# Headline input :meant to receive sequences of 100 integers,between 1 and 10000\n",
    "#Note that we can name any layer by passing it a 'name' argument\n",
    "main_input=Input(shape=(100,),dtype='int32',name='main_input')\n",
    "\n",
    "#This embedding layer will encode the input sequence\n",
    "x=Embedding(output_dim=512,input_dim=10000,input_length=100)(main_input)\n",
    "\n",
    "#A LSTM will transform the vector sequence into a single vector\n",
    "#containing information about the entire sequence\n",
    "lstm_out=LSTM(32)(x)\n",
    "\n",
    "#插入一个额外的损失，使得即使在很高的主损失的情况下，LSTM和Embedding层也能平滑的训练。\n",
    "auxiliary_output=Dense(1,activation='sigmoid',name='aux_output')(lstm_out)\n",
    "\n",
    "#将LSTM于额外的输入数据串联起来组成输入，送入模型\n",
    "auxiliary_input=Input(shape=(5,),name='aux_input')\n",
    "x=keras.layers.concatenate([lstm_out,auxiliary_input])\n",
    "\n",
    "#We stack a deep densely-connected network on top\n",
    "x=Dense(64,activation='relu')(x)\n",
    "x=Dense(64,activation='relu')(x)\n",
    "x=Dense(64,activation='relu')(x)\n",
    "\n",
    "#And finally we add the main lagoistic regression layer\n",
    "main_output=Dense(1,activation='sigmoid',name='main_output')(x)\n",
    "\n",
    "#最后，定义整个2输入，2输入的模型：\n",
    "model=Model(inputs=[main_input,auxiliary_input],outputs=[main_output,auxiliary_output])\n",
    "\n",
    "#模型定义后，编译模型。给额外的损失赋0.2的权重，可以通过关键字参数loss_weight或loss来为不同的输出设置不同的损失函数或权值。这两个参数都可以用列表\n",
    "#或字典。本例中，给loss传递单个损失函数，这个损失函数会被用在所有输出上。\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',loss_weights=[1.0,.2])\n",
    "\n",
    "#编译完成后，传递训练数据和标签进行训练\n",
    "model.fit([headline_data,additional_data],[labels,labels],epoch=50,batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为输入和输出都是被命名过的，也可以通过下面的方法编译和训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "                           loss={'main_output':'binary_crossentropy','aux_output':'binary_crossentropy'},\n",
    "                              loss_weights{'main_output':1.0,'aux_output':'0.2'})\n",
    "model.fit({'main_input':headline_data,'aux_input':additional_data},\n",
    "                  {'main_output':labels,'aux_output':labels},\n",
    "                       epoch=50,bathc_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 共享层"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑微博数据，我们希望建立模型来判别两条微博是否来自同一个用户，这个需求同样可以用来判断一个用户的两条微博的相似性。  \n",
    "一种实现方法是，建立一个模型，它分别将两条微博的数据映射到两个特征向量上，然后对特征向量串联并加在一个logistic回归层，输出它们来自同一个用户的概率。这种模型的训练数据是一对对的微博。  \n",
    "因为这个问题是对称的，所以处理第一条微博的模型当然也能用于处理第二条微博，所以我们使用一个共享的LSTM层来进行映射。  \n",
    "首先，我们将微博的数据转为（140,256）的矩阵，即每条微博有140个字符，每个单词的特征由一个256维的词向量来表示，向量的每个元素为1表示某个字符出现，为0表示不出现，这是一个one-hot编码。  \n",
    "之所以是（140,256）是因为一个微博最多有140个字符，而扩展的ASC||码表编码了常见的256个字符。当然，如果考虑中文字符，那一个单词的词向量就不止256了。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input,LSTM,Dense\n",
    "from keras.models import Model\n",
    "\n",
    "tweet_a=Input(shape=(140,256))\n",
    "tweet_b=Input(shape=(140,256))\n",
    "\n",
    "#若要对不同的输入共享同一层，就初始化改层一次，然后多次调用它\n",
    "#This layer can take as input a matrix\n",
    "#and will return a vector of size 64\n",
    "shared_lstm=LSTM(64)\n",
    "\n",
    "#when we reuse the same layer instance multiple times,the weights of the layer and also being reused\n",
    "#(it is effectively **the same** layer)\n",
    "encoded_a=shared_lstm(tweet_a)\n",
    "encoded_b=shared_lstm(tweet_b)\n",
    "\n",
    "#we can then concatenate the two vectors:\n",
    "merged_vector=keras.layers.concatenate([encoded_a,encoded_b],axis=-1)\n",
    "\n",
    "#and add a logistic regression on top\n",
    "predictions=Dense(1,activation='sigmoid')(merged_vector)\n",
    "\n",
    "#we define a trainable model linking the tweet inputs to the predictions\n",
    "model=Model(inputs=[tweet_a,tweet_b],outputs=predictions)\n",
    "model.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics='accuracy')\n",
    "model.fit([data_a,data_b],labels,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 更多的例子"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "inception的详细结构参见google 的论文 [going deeper with convolutions](http://arxiv.org/abs/1409.4842)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "\n",
    "input_img = Input(shape=(256, 256, 3))\n",
    "\n",
    "tower_1 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_1 = Conv2D(64, (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "tower_2 = Conv2D(64, (1, 1), padding='same', activation='relu')(input_img)\n",
    "tower_2 = Conv2D(64, (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(input_img)\n",
    "tower_3 = Conv2D(64, (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "output = keras.layers.concatenate([tower_1, tower_2, tower_3], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 卷积层的残差连接"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "残差网络(Residual network)的详细信息参考这篇文章[Deep Residual Learning for Image Recognition](http://arxiv.org/abs/1512.03385)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, Input\n",
    "\n",
    "# input tensor for a 3-channel 256x256 image\n",
    "x = Input(shape=(256, 256, 3))\n",
    "# 3x3 conv with 3 output channels (same as input channels)\n",
    "y = Conv2D(3, (3, 3), padding='same')(x)\n",
    "# this returns x + y.\n",
    "z = keras.layers.add([x, y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 共享视觉模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "该模型的两个输入上重用了图像处理的模型，用以判别两个mnist数字是否是相同的数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Input, Dense, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "# First, define the vision modules\n",
    "digit_input = Input(shape=(27, 27, 1))\n",
    "x = Conv2D(64, (3, 3))(digit_input)\n",
    "x = Conv2D(64, (3, 3))(x)\n",
    "x = MaxPooling2D((2, 2))(x)\n",
    "out = Flatten()(x)\n",
    "\n",
    "vision_model = Model(digit_input, out)\n",
    "\n",
    "# Then define the tell-digits-apart model\n",
    "digit_a = Input(shape=(27, 27, 1))\n",
    "digit_b = Input(shape=(27, 27, 1))\n",
    "\n",
    "# The vision model will be shared, weights and all\n",
    "out_a = vision_model(digit_a)\n",
    "out_b = vision_model(digit_b)\n",
    "\n",
    "concatenated = keras.layers.concatenate([out_a, out_b])\n",
    "out = Dense(1, activation='sigmoid')(concatenated)\n",
    "\n",
    "classification_model = Model([digit_a, digit_b], out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 视觉问答模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在针对一幅图片使用自然语言进行提问时，该模型能提供关于该图片的一个单词的答案  \n",
    "这个模型将自然语言的问题和图片分别映射为特征向量，将二者合并后训练一个logistic回归层，从一系列可能的回答中挑选一个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers import Input, LSTM, Embedding, Dense\n",
    "from keras.models import Model, Sequential\n",
    "\n",
    "# First, let's define a vision model using a Sequential model.\n",
    "# This model will encode an image into a vector.\n",
    "vision_model = Sequential()\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
    "vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "vision_model.add(MaxPooling2D((2, 2)))\n",
    "vision_model.add(Flatten())\n",
    "\n",
    "# Now let's get a tensor with the output of our vision model:\n",
    "image_input = Input(shape=(224, 224, 3))\n",
    "encoded_image = vision_model(image_input)\n",
    "\n",
    "# Next, let's define a language model to encode the question into a vector.\n",
    "# Each question will be at most 100 word long,\n",
    "# and we will index words as integers from 1 to 9999.\n",
    "question_input = Input(shape=(100,), dtype='int32')\n",
    "embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
    "encoded_question = LSTM(256)(embedded_question)\n",
    "\n",
    "# Let's concatenate the question vector and the image vector:\n",
    "merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
    "\n",
    "# And let's train a logistic regression over 1000 words on top:\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "\n",
    "# This is our final model:\n",
    "vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
    "\n",
    "# The next stage would be training this model on actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 视频问答模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在做完图片问答模型后，我么可以快速将其转为视频问答的问题。是适当的训练下，你可以为模型提供一个短视频(100帧)，然后向模型提问一个关于该视频的问题，如‘what sport is the boy palying?’->\"football\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import TimeDistributed\n",
    "\n",
    "video_input = Input(shape=(100, 224, 224, 3))\n",
    "# This is our video encoded via the previously trained vision_model (weights are reused)\n",
    "encoded_frame_sequence = TimeDistributed(vision_model)(video_input)  # the output will be a sequence of vectors\n",
    "encoded_video = LSTM(256)(encoded_frame_sequence)  # the output will be a vector\n",
    "\n",
    "# This is a model-level representation of the question encoder, reusing the same weights as before:\n",
    "question_encoder = Model(inputs=question_input, outputs=encoded_question)\n",
    "\n",
    "# Let's use it to encode the question:\n",
    "video_question_input = Input(shape=(100,), dtype='int32')\n",
    "encoded_video_question = question_encoder(video_question_input)\n",
    "\n",
    "# And this is our video question answering model:\n",
    "merged = keras.layers.concatenate([encoded_video, encoded_video_question])\n",
    "output = Dense(1000, activation='softmax')(merged)\n",
    "video_qa_model = Model(inputs=[video_input, video_question_input], outputs=output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml]",
   "language": "python",
   "name": "conda-env-ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
